# Metrics Exposer

## Nebula Graph Metrics Format

```json
// The raw metric format based on JSON
// 1. Gauge, the time serial value
// 2. Histogram, the time serial value distribution
// The raw data can be transformed to multiple specified formats (various user-defined metric formats)
// e.g.
// {
//     "name": "meta",
//     "gauges": [...],
//     "histograms:" [...],
// }
// Gauge
// {
//     "name": "xxxxx",
//     "value": 33,
//     "labels": [
//         {"name": "name", "value": "nebula"},
//         {"name": "type", "value": "qps"}
//     ]
// }
// Histogram
// {
//     "name": "xxxxx",
//     "value_range": [0, 100],
//     "buckets": [2, 3, 0, 11, ...],
//     "sum": 233,
//     "count": 332,
//     "labels": [
//         {"name": "name", "value": "nebula"},
//         {"name": "type", "value": "latency"}
//     ]
// }
```

As shown above, **Nebula Graph** exposes JSON-based data under the `/metrics` directory of each HTTP service. You can convert the data into a format that can be interpreted by your own system.

**Nebula Graph** supports Prometheus. If you are using Prometheus, please refer to the following session to get started.

## Accessing to Prometheus

### Access Method

Prometheus supports fetching metrics with `push/pull`. **Nebula Graph** only supports `pull`. In the pull mode, Prometheus pulls metrics data periodically from certain endpoints via HTTP requests.

### Starting Nebula Graph

Refer to [Get Started](https://github.com/vesoft-inc/nebula/blob/master/docs/manual-CN/1.overview/2.quick-start/1.get-started.md) to start **Nebula Graph** services.

### Starting nebula-prom-transformer

nebula-prom-transformer is a tool that converts **Nebula Graph** metrics into Prometheus interpretable format. It pulls data from **Nebula Graph** and exposes the data endpoints. You can configure Prometheus to pull data from the specified endpoints by referring to the [README](https://github.com/Shylock-Hg/nebula-prom-transformer) documentation.

### Configuring and Start Prometheus

This section introduces how to configure Prometheus and make it pull metrics data from the configured endpoints. For details on Prometheus installation and configuration, please refer to Prometheus [Official Documentation](https://prometheus.io/docs/prometheus/latest/getting_started/). In this section, we only modify the endpoints that pull the metrics data. An example configuration file `prometheus.yml` is as follows.

```yaml
# my global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any time series scraped from this config.
  - job_name: 'prometheus'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
    - targets: ['localhost:11001', 'localhost:12001', 'localhost:13001']
```

As shown above, for default configuration **Nebula Graph**, i.e. the single node, we only need to start three nebula-prom-transformer services to pull **Nebula Graph** metrics data and monitor the 11000, 12000, and 13000 endpoints data. For non-default configuration or clusters, you need to expose all the HTTP endpoints of all services to Prometheus.

### Checking Metrics via Prometheus

After executing the above three steps successfully, all the configurations are completed and **Nebula Graph** and Prometheus are connected. Now you can access the graphical operation interface provided by Prometheus through a browser.

1. Input `http: // localhost: 9090` in the browser.
2. Input `add_edges_latency_bucket` in the query box of Prometheus.
3. Click the `execute` button to check the corresponding metrics values.

Consider the following example:

![image](https://user-images.githubusercontent.com/42762957/71470522-699cfe80-2807-11ea-9013-ea392b3f2aa1.png)

### Accessing to OpenTSDB (Optional, not recommend)

In addition to the Prometheus storage engine, **Nebula Graph** also supports a variety of third-party storage engines (Prometheus is preferred if there are no special requirements). One example is OpenTSDB. Prometheus supports writing data to OpenTSDB, but does not support reading queries from OpenTSDB.

The topology of access to OpenTSDB is shown below:

```yaml
Prometheus --> RemoteAdaptor --> OpenTSDB
```

Prometheus provides a third-party storage adapter to write Prometheus data to the third-party storages.

Accessing steps:

1. Start Prometheus
2. Start OpenTSDBï¼Œyou can refer to the [Installation Documentation](http://opentsdb.net/docs/build/html/installation.html) or [Install with Docker](https://hub.docker.com/r/opentsdb/opentsdb)
3. Install Go, you can refer to the [Go Installation](https://golang.org/doc/install)
4. Compile and start Prometheus, you can refer to the [Remote Storage Adapter](https://github.com/prometheus/prometheus/tree/master/documentation/examples/remote_storage/remote_storage_adapter)

```bash
git clone --depth 1 https://github.com/prometheus/prometheus.git
cd prometheus/documentation/examples/remote_storage/remote_storage_adapter
go build
./remote_storage_adapter --opentsdb-url=http://localhost:8081/
```

Then data in Prometheus can be written into OpenTSDB.

**Note:** The `go build` may fail due to network problems. Please refer to [goproxy Documentation](https://github.com/goproxy/goproxy.cn) for solutions.
